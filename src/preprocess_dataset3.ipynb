{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "99dff001-2d77-43bb-b23e-e8d74e12bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import os\n",
    "# import json\n",
    "# from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "964233dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Preprocessing\n",
    "import re\n",
    "import preprocessor as p\n",
    "import string\n",
    "import contractions\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "# Model\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "e7b8f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cgab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cgab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\cgab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cgab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cgab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download requires corpus\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2879a174-73c4-4294-a7e0-a5879f52320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators</th>\n",
       "      <th>post_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1179055004553900032_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179063826874032128_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178793830532956161_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 4, 'targe...</td>\n",
       "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179088797964763136_twitter</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 1, 't...</td>\n",
       "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179085312976445440_twitter</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 4, 't...</td>\n",
       "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    annotators  \\\n",
       "1179055004553900032_twitter  [{'label': 'normal', 'annotator_id': 1, 'targe...   \n",
       "1179063826874032128_twitter  [{'label': 'normal', 'annotator_id': 1, 'targe...   \n",
       "1178793830532956161_twitter  [{'label': 'normal', 'annotator_id': 4, 'targe...   \n",
       "1179088797964763136_twitter  [{'label': 'hatespeech', 'annotator_id': 1, 't...   \n",
       "1179085312976445440_twitter  [{'label': 'hatespeech', 'annotator_id': 4, 't...   \n",
       "\n",
       "                                                                   post_tokens  \n",
       "1179055004553900032_twitter  [i, dont, think, im, getting, my, baby, them, ...  \n",
       "1179063826874032128_twitter  [we, cannot, continue, calling, ourselves, fem...  \n",
       "1178793830532956161_twitter                [nawt, yall, niggers, ignoring, me]  \n",
       "1179088797964763136_twitter  [<user>, i, am, bit, confused, coz, chinese, p...  \n",
       "1179085312976445440_twitter  [this, bitch, in, whataburger, eating, a, burg...  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(\"../res/dataset3.json\")\n",
    "dataset = dataset.transpose()\n",
    "dataset.drop([\"post_id\", \"rationales\"], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "107556c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing function\n",
    "def preprocess(text):\n",
    "    # twitter-presprocessor\n",
    "    text = p.clean(text)\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    # Expand Contractions\n",
    "    expanded = []\n",
    "    for word in text.split():\n",
    "        expanded.append(contractions.fix(word, slang=True))\n",
    "    text = ' '.join(expanded)\n",
    "    # Remove punctuation marks\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenization\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    lemmanized = preprocess_part2(text)\n",
    "\n",
    "    # return str(text)\n",
    "    return lemmanized\n",
    "\n",
    "def preprocess_part2(text):\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(text):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords_updated and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    return str(Final_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5b9d1",
   "metadata": {},
   "source": [
    "<h2>Preprocess post_tokens</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "554d7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracketed_words = set()\n",
    "# Regex pattern to match anything that is eclosed by angled brackets\n",
    "pattern = re.compile(\"\\<(.*?)\\>\")\n",
    "# Get all unique bracketed tokens\n",
    "for e in dataset[\"post_tokens\"]:\n",
    "    for t in e:\n",
    "        if \">\" in t and \"<\" in t:\n",
    "            bracketed_words.add(t)\n",
    "# Remove all bracketed tokens in post_tokens\n",
    "dataset[\"post_tokens\"] = [list(filter(lambda token: token not in bracketed_words, entry)) for entry in dataset[\"post_tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "20d374ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions\n",
    "dataset[\"post_tokens\"] = [[contractions.fix(token, slang=True) for token in entry] for entry in dataset[\"post_tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "ddff60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for concatenated text\n",
    "dataset[\"text\"] = [' '.join(entry) for entry in dataset[\"post_tokens\"]]\n",
    "# Convert to lowercase\n",
    "dataset[\"text\"] = [entry.lower() for entry in dataset[\"text\"]]\n",
    "# Remove punctuation marks\n",
    "dataset[\"text\"] = [entry.translate(str.maketrans('', '', string.punctuation)) for entry in dataset[\"text\"]]\n",
    "# Tokenization\n",
    "dataset['text']= [word_tokenize(entry) for entry in dataset['text']]\n",
    "# Turn to String\n",
    "dataset['text']= [str(entry) for entry in dataset['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "21d96da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"post_tokens\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "3a098af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1179055004553900032_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>['i', 'do', 'not', 'think', 'i', 'am', 'gettin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179063826874032128_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>['we', 'can', 'not', 'continue', 'calling', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178793830532956161_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 4, 'targe...</td>\n",
       "      <td>['nawt', 'you', 'all', 'niggers', 'ignoring', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179088797964763136_twitter</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 1, 't...</td>\n",
       "      <td>['i', 'am', 'bit', 'confused', 'coz', 'chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179085312976445440_twitter</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 4, 't...</td>\n",
       "      <td>['this', 'bitch', 'in', 'whataburger', 'eating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    annotators  \\\n",
       "1179055004553900032_twitter  [{'label': 'normal', 'annotator_id': 1, 'targe...   \n",
       "1179063826874032128_twitter  [{'label': 'normal', 'annotator_id': 1, 'targe...   \n",
       "1178793830532956161_twitter  [{'label': 'normal', 'annotator_id': 4, 'targe...   \n",
       "1179088797964763136_twitter  [{'label': 'hatespeech', 'annotator_id': 1, 't...   \n",
       "1179085312976445440_twitter  [{'label': 'hatespeech', 'annotator_id': 4, 't...   \n",
       "\n",
       "                                                                          text  \n",
       "1179055004553900032_twitter  ['i', 'do', 'not', 'think', 'i', 'am', 'gettin...  \n",
       "1179063826874032128_twitter  ['we', 'can', 'not', 'continue', 'calling', 'o...  \n",
       "1178793830532956161_twitter  ['nawt', 'you', 'all', 'niggers', 'ignoring', ...  \n",
       "1179088797964763136_twitter  ['i', 'am', 'bit', 'confused', 'coz', 'chinese...  \n",
       "1179085312976445440_twitter  ['this', 'bitch', 'in', 'whataburger', 'eating...  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "9720a918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'label': 'normal', 'annotator_id': 1, 'target': ['None']}, {'label': 'normal', 'annotator_id': 2, 'target': ['None']}, {'label': 'normal', 'annotator_id': 3, 'target': ['None']}]\""
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dataset.annotators.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "9e0a114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_hate(text):\n",
    "    return 1 if \"hatespeech\" in text else 0\n",
    "def det_normal(text):\n",
    "    return 1 if \"normal\" in text and \"hatespeech\" not in text else 0\n",
    "def det_offensive(text):\n",
    "    return 1 if \"offensive\" in text else 0\n",
    "\n",
    "dataset[\"HATE\"] = dataset.apply(lambda e: det_hate(str(e[0])), axis = 1)\n",
    "dataset[\"NOT\"] = dataset.apply(lambda e: det_normal(str(e[0])), axis = 1)\n",
    "dataset[\"OFFN\"] = dataset.apply(lambda e: det_offensive(str(e[0])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for concatenated text\n",
    "dataset[\"text\"] = [' '.join(entry) for entry in dataset[\"post_tokens\"]]\n",
    "# Convert to lowercase\n",
    "dataset[\"text\"] = [entry.lower() for entry in dataset[\"text\"]]\n",
    "# Remove punctuation marks\n",
    "dataset[\"text\"] = [entry.translate(str.maketrans('', '', string.punctuation)) for entry in dataset[\"text\"]]\n",
    "# Tokenization\n",
    "dataset['text']= [word_tokenize(entry) for entry in dataset['text']]\n",
    "# Turn to String\n",
    "dataset['text']= [str(entry) for entry in dataset['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d3838877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate if there are rows with HATE 1 and NOT 1\n",
    "dataset1 = dataset[dataset[\"HATE\"].ne(0) & dataset[\"NOT\"].ne(0)]\n",
    "len(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "9dce8098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3582"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get collection of obscene words\n",
    "obscene_words = []\n",
    "# Read file\n",
    "with open('../res/obscene-words.csv') as file: \n",
    "    for line in file:\n",
    "        obscene_words.append(line.rstrip(\"\\n\"))\n",
    "obscene_words = obscene_words[0].split(\", \")\n",
    "\n",
    "# Remove containing numbers\n",
    "obscene_words = [x for x in obscene_words if not any(c.isdigit() for c in x)]\n",
    "# Remove containing special characters\n",
    "special_characters = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "def has_special(text):\n",
    "    return True if any(c in special_characters for c in text) else 0\n",
    "obscene_words = list(filter(lambda x: not has_special(x), obscene_words))\n",
    "# Remove spaces\n",
    "obscene_words = list(filter(lambda x: \" \" not in x, obscene_words))\n",
    "len(obscene_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "a59bd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_prof(text):\n",
    "    return 1 if any(badword in text for badword in obscene_words) else 0\n",
    "\n",
    "dataset[\"PRFN\"] = dataset.apply(lambda e: det_prof(str(e[1])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "23b9a3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17269\n",
       "0     2879\n",
       "Name: PRFN, dtype: int64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"PRFN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0fe99de9-178a-4a3d-9d0f-da221b1b4238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1179055004553900032_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179063826874032128_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178793830532956161_twitter</th>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 4, 'targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179088797964763136_twitter</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 1, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179085312976445440_twitter</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 4, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989999_gab</th>\n",
       "      <td>[{'label': 'offensive', 'annotator_id': 217, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990225_gab</th>\n",
       "      <td>[{'label': 'offensive', 'annotator_id': 220, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991681_gab</th>\n",
       "      <td>[{'label': 'offensive', 'annotator_id': 206, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992513_gab</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 209, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998729_gab</th>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 200, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    annotators\n",
       "1179055004553900032_twitter  [{'label': 'normal', 'annotator_id': 1, 'targe...\n",
       "1179063826874032128_twitter  [{'label': 'normal', 'annotator_id': 1, 'targe...\n",
       "1178793830532956161_twitter  [{'label': 'normal', 'annotator_id': 4, 'targe...\n",
       "1179088797964763136_twitter  [{'label': 'hatespeech', 'annotator_id': 1, 't...\n",
       "1179085312976445440_twitter  [{'label': 'hatespeech', 'annotator_id': 4, 't...\n",
       "...                                                                        ...\n",
       "9989999_gab                  [{'label': 'offensive', 'annotator_id': 217, '...\n",
       "9990225_gab                  [{'label': 'offensive', 'annotator_id': 220, '...\n",
       "9991681_gab                  [{'label': 'offensive', 'annotator_id': 206, '...\n",
       "9992513_gab                  [{'label': 'hatespeech', 'annotator_id': 209, ...\n",
       "9998729_gab                  [{'label': 'hatespeech', 'annotator_id': 200, ...\n",
       "\n",
       "[20148 rows x 1 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dict = pd.DataFrame.from_dict(dataset[\"annotators\"])\n",
    "get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "e44ea7a3-0a71-4bbb-8471-a008e0d5acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20148"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ = dataset[\"annotators\"].to_list()\n",
    "list_[0:5]\n",
    "len(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2362510a-4061-4109-9849-0ed49950d77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60444"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = [val for sublist in list_ for val in sublist]\n",
    "flatten[0:5]\n",
    "len(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "bf579418-5b61-448c-a9ba-bd33013db017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>3</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60439</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>253</td>\n",
       "      <td>[Asian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60440</th>\n",
       "      <td>offensive</td>\n",
       "      <td>222</td>\n",
       "      <td>[Asian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60441</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>200</td>\n",
       "      <td>[African, Islam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60442</th>\n",
       "      <td>offensive</td>\n",
       "      <td>202</td>\n",
       "      <td>[Islam, Jewish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60443</th>\n",
       "      <td>offensive</td>\n",
       "      <td>207</td>\n",
       "      <td>[African, Islam, Jewish]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60444 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  annotator_id                    target\n",
       "0          normal             1                    [None]\n",
       "1          normal             2                    [None]\n",
       "2          normal             3                    [None]\n",
       "3          normal             1                    [None]\n",
       "4          normal             2                    [None]\n",
       "...           ...           ...                       ...\n",
       "60439  hatespeech           253                   [Asian]\n",
       "60440   offensive           222                   [Asian]\n",
       "60441  hatespeech           200          [African, Islam]\n",
       "60442   offensive           202           [Islam, Jewish]\n",
       "60443   offensive           207  [African, Islam, Jewish]\n",
       "\n",
       "[60444 rows x 3 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator = pd.DataFrame(flatten)\n",
    "# annotator.drop([\"annotator_id\"], axis=1, inplace=True)\n",
    "annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "4a75f292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotator.annotator_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "95ceaa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        24449\n",
       "hatespeech    18070\n",
       "offensive     17925\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7ecc2e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20148"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "72504ea9-8c65-417f-8055-5825897994d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotator = dataset.drop(dataset.columns[[0,2]], axis = 1 ).join(annotator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "793c499d-4944-43be-991c-d949546a1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None            21314\n",
       "African         10015\n",
       "Islam            6686\n",
       "Women            6126\n",
       "Jewish           5961\n",
       "Homosexual       5617\n",
       "Other            4708\n",
       "Refugee          3100\n",
       "Arab             2907\n",
       "Caucasian        2359\n",
       "Men              1758\n",
       "Asian            1350\n",
       "Hispanic         1299\n",
       "Christian         270\n",
       "Disability        221\n",
       "Minority          188\n",
       "Heterosexual      141\n",
       "Economic           90\n",
       "Hindu              89\n",
       "Nonreligious       87\n",
       "Indigenous         83\n",
       "Indian             81\n",
       "Buddhism           12\n",
       "Bisexual            8\n",
       "Asexual             5\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator['target'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "52a5e0b0-5663-4a5c-bccc-b4735aefe390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        24449\n",
       "hatespeech    18070\n",
       "offensive     17925\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator['label'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1e3b31f1-a7fe-4f0a-8811-8487560e8121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>target</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>normal</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>3</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60439</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>253</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60440</th>\n",
       "      <td>offensive</td>\n",
       "      <td>222</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60441</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>200</td>\n",
       "      <td>[African, Islam]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60442</th>\n",
       "      <td>offensive</td>\n",
       "      <td>202</td>\n",
       "      <td>[Islam, Jewish]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60443</th>\n",
       "      <td>offensive</td>\n",
       "      <td>207</td>\n",
       "      <td>[African, Islam, Jewish]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60444 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  annotator_id                    target  hatespeech  normal  \\\n",
       "0          normal             1                    [None]           0       1   \n",
       "1          normal             2                    [None]           0       1   \n",
       "2          normal             3                    [None]           0       1   \n",
       "3          normal             1                    [None]           0       1   \n",
       "4          normal             2                    [None]           0       1   \n",
       "...           ...           ...                       ...         ...     ...   \n",
       "60439  hatespeech           253                   [Asian]           1       0   \n",
       "60440   offensive           222                   [Asian]           0       0   \n",
       "60441  hatespeech           200          [African, Islam]           1       0   \n",
       "60442   offensive           202           [Islam, Jewish]           0       0   \n",
       "60443   offensive           207  [African, Islam, Jewish]           0       0   \n",
       "\n",
       "       offensive  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "60439          0  \n",
       "60440          1  \n",
       "60441          0  \n",
       "60442          1  \n",
       "60443          1  \n",
       "\n",
       "[60444 rows x 6 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = annotator['label']\n",
    "annotator = annotator.join(label.str.get_dummies().astype('int32'))\n",
    "annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1e4ed718-8b3d-4112-82c7-c837e5091fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Race = African, Arab, Caucasian, Asian, Hispanic, Indian\n",
    "#Religion = Islam, Jewish, Christian, Hindu, Nonreligious, Buddhism\n",
    "#Gender = Women, Homosexual, Men, Heterosexual, Bisexual, Asexual\n",
    "#Other = Other, Refugee, Disability, Minority, Economic, Indigenous\n",
    "#None = None\n",
    "\n",
    "#Race = annotator.loc[annotator['target'].isin(['African', 'Arab', 'Caucasian', 'Asian', 'Hispanic', 'Indian'])]\n",
    "#Race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4904e-a30d-485a-94af-80305227840e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fad1b-908a-4d95-8897-444d1c5c1346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
