{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../out/true-final-3500/\"\n",
    "t1 = joblib.load(path + 't1.joblib.z')\n",
    "t1ngram = joblib.load(path + 't1ngram.joblib.z')\n",
    "t2 = joblib.load(path + 't2.joblib.z')\n",
    "t2ngram = joblib.load(path + 't2ngram.joblib.z')\n",
    "t3ovr = joblib.load(path + 't3ovr.joblib.z')\n",
    "t3ovrngram = joblib.load(path + 't3ovr_ngram.joblib.z')\n",
    "t3bc = joblib.load(path + 't3bc.joblib.z')\n",
    "t3cc = joblib.load(path + 't3cc.joblib.z')\n",
    "t3lp = joblib.load(path + 't3lp.joblib.z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"../res/val_final_3500.csv\")\n",
    "val_text = val_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_models = [t1, t1ngram]\n",
    "t1_names = [\"t1\", \"t1ngram\"]\n",
    "t2_models = [t2, t2ngram]\n",
    "t2_names = [\"t2\", \"t2ngram\"]\n",
    "t3_models = [t3ovr, t3ovrngram, t3bc, t3cc, t3lp]\n",
    "t3_names = [\"t3ovr\", \"t3ovrngram\", \"t3bc\", \"t3cc\", \"t3lp\"]\n",
    "\n",
    "t1_predictions = []\n",
    "t1_predictions_proba = []\n",
    "t2_predictions = []\n",
    "t3_predictions = []\n",
    "\n",
    "t1_targets = ['subtask1']\n",
    "t1_targets_proba = [\"HATE\",\"NOT\",\"OFFN\"]\n",
    "t2_targets = ['PRFN']\n",
    "t3_targets = ['Race', 'Religion', 'Gender', 'Other', 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(t1_models):\n",
    "    predicts = x.predict(val_text)\n",
    "    t1_predictions.append(predicts)\n",
    "\n",
    "for i,x in enumerate(t1_models):\n",
    "    predicts = x.predict_proba(val_text)\n",
    "    t1_predictions_proba.append(predicts)\n",
    "\n",
    "for i,x in enumerate(t2_models):\n",
    "    predicts = x.predict(val_text)\n",
    "    t2_predictions.append(predicts)\n",
    "\n",
    "for i,x in enumerate(t3_models):\n",
    "    predicts = x.predict(val_text)\n",
    "    t3_predictions.append(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- t1 accuracies: -----\n",
      "t1 - 61.1429\n",
      "t1ngram - 61.4286\n",
      "----- t2 accuracies: -----\n",
      "t2 - 86.8571\n",
      "t2ngram - 86.2857\n",
      "-----t3 accuracies: -----\n",
      "t3ovr - 44.8571\n",
      "t3ovrngram - 44.5714\n",
      "t3bc - 44.8571\n",
      "t3cc - 54.0\n",
      "t3lp - 52.8571\n"
     ]
    }
   ],
   "source": [
    "print(\"----- t1 accuracies: -----\")\n",
    "for i,x in enumerate(t1_predictions):\n",
    "    acc = round(accuracy_score(x, val_df[t1_targets])*100,4)\n",
    "    print(f\"{t1_names[i]} - {str(acc)}\")\n",
    "\n",
    "print(\"----- t2 accuracies: -----\")\n",
    "for i,x in enumerate(t2_predictions):\n",
    "    acc = round(accuracy_score(x, val_df[t2_targets])*100,4)\n",
    "    print(f\"{t2_names[i]} - {str(acc)}\")\n",
    "\n",
    "print(\"-----t3 accuracies: -----\")\n",
    "for i,x in enumerate(t3_predictions):\n",
    "    acc = round(accuracy_score(x, val_df[t3_targets])*100,4)\n",
    "    print(f\"{t3_names[i]} - {str(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HATE</th>\n",
       "      <th>NOT</th>\n",
       "      <th>OFFN</th>\n",
       "      <th>PRFN</th>\n",
       "      <th>Race</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Other</th>\n",
       "      <th>None</th>\n",
       "      <th>subtask1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unapologetically american i like legal immigra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OFFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what with this racist coon nurse a murderess h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what the fuck is this nigger announcer on nhl ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who the fuck is goatfucker hamed halts maul du...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>labour negress says prince charles unfit this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  HATE  NOT  OFFN  PRFN  \\\n",
       "0  unapologetically american i like legal immigra...     0    0     1     1   \n",
       "1  what with this racist coon nurse a murderess h...     1    0     0     1   \n",
       "2  what the fuck is this nigger announcer on nhl ...     1    0     0     1   \n",
       "3  who the fuck is goatfucker hamed halts maul du...     1    0     0     1   \n",
       "4  labour negress says prince charles unfit this ...     1    0     0     1   \n",
       "\n",
       "   Race  Religion  Gender  Other  None subtask1  \n",
       "0     0         0       0      1     0     OFFN  \n",
       "1     1         0       0      0     0     HATE  \n",
       "2     1         0       0      0     0     HATE  \n",
       "3     1         0       0      0     0     HATE  \n",
       "4     1         0       1      0     0     HATE  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- t1 report: -----\n",
      "------------------- t1 -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HATE       0.65      0.71      0.68       105\n",
      "         NOT       0.61      0.70      0.65       134\n",
      "        OFFN       0.57      0.41      0.47       111\n",
      "\n",
      "    accuracy                           0.61       350\n",
      "   macro avg       0.61      0.61      0.60       350\n",
      "weighted avg       0.61      0.61      0.60       350\n",
      "\n",
      "------------------- t1ngram -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HATE       0.60      0.70      0.65       105\n",
      "         NOT       0.65      0.71      0.68       134\n",
      "        OFFN       0.58      0.41      0.48       111\n",
      "\n",
      "    accuracy                           0.61       350\n",
      "   macro avg       0.61      0.61      0.60       350\n",
      "weighted avg       0.61      0.61      0.61       350\n",
      "\n",
      "----- t2 report: -----\n",
      "------------------- t2 -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.11      0.18        47\n",
      "           1       0.88      0.99      0.93       303\n",
      "\n",
      "    accuracy                           0.87       350\n",
      "   macro avg       0.72      0.55      0.55       350\n",
      "weighted avg       0.83      0.87      0.83       350\n",
      "\n",
      "------------------- t2ngram -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.11      0.17        47\n",
      "           1       0.88      0.98      0.93       303\n",
      "\n",
      "    accuracy                           0.86       350\n",
      "   macro avg       0.67      0.54      0.55       350\n",
      "weighted avg       0.82      0.86      0.82       350\n",
      "\n",
      "----- t3 report: -----\n",
      "------------------- t3ovr -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Race       0.84      0.57      0.68        94\n",
      "    Religion       0.82      0.62      0.70        81\n",
      "      Gender       0.61      0.34      0.44        58\n",
      "       Other       0.78      0.24      0.37        29\n",
      "        None       0.67      0.46      0.55       112\n",
      "\n",
      "   micro avg       0.75      0.49      0.59       374\n",
      "   macro avg       0.74      0.45      0.55       374\n",
      "weighted avg       0.74      0.49      0.58       374\n",
      " samples avg       0.84      0.53      0.50       374\n",
      "\n",
      "------------------- t3ovrngram -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Race       0.83      0.61      0.70        94\n",
      "    Religion       0.83      0.60      0.70        81\n",
      "      Gender       0.62      0.41      0.49        58\n",
      "       Other       0.70      0.24      0.36        29\n",
      "        None       0.66      0.40      0.50       112\n",
      "\n",
      "   micro avg       0.74      0.49      0.59       374\n",
      "   macro avg       0.73      0.45      0.55       374\n",
      "weighted avg       0.74      0.49      0.58       374\n",
      " samples avg       0.83      0.52      0.50       374\n",
      "\n",
      "------------------- t3bc -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Race       0.84      0.57      0.68        94\n",
      "    Religion       0.82      0.62      0.70        81\n",
      "      Gender       0.61      0.34      0.44        58\n",
      "       Other       0.78      0.24      0.37        29\n",
      "        None       0.67      0.46      0.55       112\n",
      "\n",
      "   micro avg       0.75      0.49      0.59       374\n",
      "   macro avg       0.74      0.45      0.55       374\n",
      "weighted avg       0.74      0.49      0.58       374\n",
      " samples avg       0.84      0.53      0.50       374\n",
      "\n",
      "------------------- t3cc -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Race       0.84      0.57      0.68        94\n",
      "    Religion       0.82      0.62      0.70        81\n",
      "      Gender       0.60      0.36      0.45        58\n",
      "       Other       0.70      0.24      0.36        29\n",
      "        None       0.45      0.75      0.56       112\n",
      "\n",
      "   micro avg       0.61      0.58      0.59       374\n",
      "   macro avg       0.68      0.51      0.55       374\n",
      "weighted avg       0.67      0.58      0.59       374\n",
      " samples avg       0.60      0.62      0.58       374\n",
      "\n",
      "------------------- t3lp -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Race       0.73      0.57      0.64        94\n",
      "    Religion       0.81      0.59      0.69        81\n",
      "      Gender       0.60      0.31      0.41        58\n",
      "       Other       0.73      0.28      0.40        29\n",
      "        None       0.47      0.74      0.57       112\n",
      "\n",
      "   micro avg       0.60      0.56      0.58       374\n",
      "   macro avg       0.67      0.50      0.54       374\n",
      "weighted avg       0.65      0.56      0.58       374\n",
      " samples avg       0.60      0.62      0.58       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----- t1 report: -----\")\n",
    "for i,x in enumerate(t1_predictions):\n",
    "    report = classification_report(y_pred=x,\n",
    "            y_true=val_df[t1_targets], \n",
    "            zero_division = 1)\n",
    "    print(f\"------------------- {t1_names[i]} -------------------\")\n",
    "    print(report)\n",
    "\n",
    "print(\"----- t2 report: -----\")\n",
    "for i,x in enumerate(t2_predictions):\n",
    "    report = classification_report(y_pred=x,\n",
    "            y_true=val_df[t2_targets], \n",
    "            zero_division = 1)\n",
    "    print(f\"------------------- {t2_names[i]} -------------------\")\n",
    "    print(report)\n",
    "\n",
    "print(\"----- t3 report: -----\")\n",
    "for i,x in enumerate(t3_predictions):\n",
    "    report = classification_report(y_pred=x,\n",
    "            y_true=val_df[t3_targets], \n",
    "            target_names=t3_targets,\n",
    "            zero_division = 1)\n",
    "    print(f\"------------------- {t3_names[i]} -------------------\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- t1 AUROC: -----\n",
      "t1 - 0.7740418048603513\n",
      "t1ngram - 0.7862729842019825\n",
      "----- t2 AUROC: -----\n",
      "t2 - 0.5465908292956956\n",
      "t2ngram - 0.5432904992626922\n",
      "----- t3 AUROC: -----\n",
      "t3ovr - 0.7152642862102714\n",
      "t3ovrngram - 0.7145836739033432\n",
      "t3bc - 0.7152642862102714\n",
      "t3cc - 0.7111818280572407\n",
      "t3lp - 0.7051525381592801\n"
     ]
    }
   ],
   "source": [
    "print(\"----- t1 AUROC: -----\")\n",
    "for i,x in enumerate(t1_predictions_proba):\n",
    "    roc = roc_auc_score(y_true=val_df[t1_targets_proba], \n",
    "        y_score=x,\n",
    "        average='weighted')\n",
    "    print(f\"{t1_names[i]} - {str(roc)}\")\n",
    "\n",
    "print(\"----- t2 AUROC: -----\")\n",
    "for i,x in enumerate(t2_predictions):\n",
    "    roc = roc_auc_score(y_true=val_df[t2_targets], \n",
    "        y_score=x,\n",
    "        average='weighted')\n",
    "    print(f\"{t2_names[i]} - {str(roc)}\")\n",
    "\n",
    "print(\"----- t3 AUROC: -----\")\n",
    "for i,x in enumerate(t3_predictions):\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true=val_df[t3_targets], \n",
    "            y_score=x,\n",
    "            average='weighted')\n",
    "    except: # If prediction scores are in a sparse array, convert it to an array\n",
    "        roc = roc_auc_score(y_true=val_df[t3_targets], \n",
    "            y_score=x.toarray(),\n",
    "            average='weighted')\n",
    "    print(f\"{t3_names[i]} - {str(roc)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683bf24e2bbf755c5f996764453fd2964c8a281735da13ddd37f4df27ea665f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
